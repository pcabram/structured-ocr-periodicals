{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold Standard Preparation - Stage 1\n",
      "============================================================\n",
      "Project root: /home/fabian-ramirez/Documents/These/Code/magazine_graphs\n",
      "\n",
      "Directories:\n",
      "  Predictions: /home/fabian-ramirez/Documents/These/Code/magazine_graphs/data/predictions\n",
      "  Gold raw:    /home/fabian-ramirez/Documents/These/Code/magazine_graphs/data/gold_standard/raw\n",
      "  Gold clean:  /home/fabian-ramirez/Documents/These/Code/magazine_graphs/data/gold_standard/cleaned\n",
      "  Schema:      Stage1PageModel\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gold Standard Preparation - Stage 1 OCR\n",
    "\n",
    "Prepares prediction files for manual annotation and validates corrected gold standard.\n",
    "\n",
    "Input:  Predictions from data/predictions/{magazine_name}/\n",
    "Output: Gold standard in data/gold_standard/{raw|cleaned}/{magazine_name}/\n",
    "Schema: schemas/stage1_page.py\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "from typing import Dict, List\n",
    "from collections import Counter\n",
    "\n",
    "# Project imports\n",
    "from utils.paths import PROJECT_ROOT, PREDICTIONS, GOLD_RAW, GOLD_CLEAN, ensure_data_dirs\n",
    "from schemas.stage1_page import Stage1PageModel\n",
    "\n",
    "# Ensure directories exist\n",
    "ensure_data_dirs()\n",
    "\n",
    "# Centralized paths\n",
    "PRED_ROOT = PREDICTIONS\n",
    "GOLD_ROOT = GOLD_RAW.parent \n",
    "\n",
    "print(\"Gold Standard Preparation - Stage 1\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(\"\\nDirectories:\")\n",
    "print(f\"  Predictions: {PRED_ROOT}\")\n",
    "print(f\"  Gold raw:    {GOLD_RAW}\")\n",
    "print(f\"  Gold clean:  {GOLD_CLEAN}\")\n",
    "print(f\"  Schema:      {Stage1PageModel.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying predictions for annotation...\n",
      "\n",
      "✓ La_Plume_bpt6k1185893k_1_10_1889: 0 copied, 14 skipped\n",
      "✓ La_Plume_bpt6k1212187t_15-11-1893: 0 copied, 34 skipped\n",
      "Attention: backup: No JSON files found\n",
      "\n",
      "============================================================\n",
      "Copy Summary\n",
      "============================================================\n",
      "Magazines processed: 2\n",
      "Files copied:        0\n",
      "Files skipped:       48\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Copy Predictions for Annotation\n",
    "\"\"\"\n",
    "\n",
    "def copy_for_annotation(\n",
    "    pred_root: Path,\n",
    "    gold_raw: Path,\n",
    "    overwrite: bool = False\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Copy prediction files to gold_standard/raw/ for annotation.\n",
    "    \n",
    "    Processes all magazine directories in predictions/.\n",
    "    Skips files that already exist unless overwrite=True.\n",
    "    \n",
    "    Args:\n",
    "        pred_root: Root predictions directory\n",
    "        gold_raw: Gold standard raw directory\n",
    "        overwrite: If True, overwrite existing files\n",
    "    \n",
    "    Returns:\n",
    "        Statistics: {magazine_name: {'copied': n, 'skipped': n}}\n",
    "    \"\"\"\n",
    "    # Find all magazine directories in predictions\n",
    "    magazine_dirs = [d for d in pred_root.iterdir() if d.is_dir()]\n",
    "    \n",
    "    if not magazine_dirs:\n",
    "        print(\"No magazine directories found in predictions/\")\n",
    "        return {}\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    for mag_dir in sorted(magazine_dirs):\n",
    "        magazine_name = mag_dir.name\n",
    "        dest_dir = gold_raw / magazine_name\n",
    "        dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        json_files = list(mag_dir.glob(\"*.json\"))\n",
    "        \n",
    "        if not json_files:\n",
    "            print(f\"Attention: {magazine_name}: No JSON files found\")\n",
    "            continue\n",
    "        \n",
    "        mag_stats = {'copied': 0, 'skipped': 0}\n",
    "        \n",
    "        for json_file in sorted(json_files):\n",
    "            dest_file = dest_dir / json_file.name\n",
    "            \n",
    "            if dest_file.exists() and not overwrite:\n",
    "                mag_stats['skipped'] += 1\n",
    "            else:\n",
    "                shutil.copy2(json_file, dest_file)\n",
    "                mag_stats['copied'] += 1\n",
    "        \n",
    "        stats[magazine_name] = mag_stats\n",
    "        \n",
    "        print(f\"✓ {magazine_name}: {mag_stats['copied']} copied, {mag_stats['skipped']} skipped\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Run copy\n",
    "print(\"Copying predictions for annotation...\")\n",
    "print()\n",
    "copy_stats = copy_for_annotation(PRED_ROOT, GOLD_RAW, overwrite=False)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"Copy Summary\")\n",
    "print(\"=\" * 60)\n",
    "total_copied = sum(s['copied'] for s in copy_stats.values())\n",
    "total_skipped = sum(s['skipped'] for s in copy_stats.values())\n",
    "print(f\"Magazines processed: {len(copy_stats)}\")\n",
    "print(f\"Files copied:        {total_copied}\")\n",
    "print(f\"Files skipped:       {total_skipped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Validate Gold Standard\n",
      "============================================================\n",
      "\n",
      "La_Plume_bpt6k1185893k_1_10_1889: 14/14 valid\n",
      "La_Plume_bpt6k1212187t_15-11-1893: 1/1 valid\n",
      "\n",
      "============================================================\n",
      "Summary\n",
      "============================================================\n",
      "Valid:   15\n",
      "Invalid: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Validate Gold Standard Files\n",
    "\"\"\"\n",
    "\n",
    "def validate_gold_standard(gold_clean: Path) -> Dict:\n",
    "    \"\"\"\n",
    "    Validate all JSON files in gold_standard/cleaned/ against schema.\n",
    "    \n",
    "    Args:\n",
    "        gold_clean: Gold standard cleaned directory\n",
    "    \n",
    "    Returns:\n",
    "        Validation results by magazine\n",
    "    \"\"\"\n",
    "    magazine_dirs = [d for d in gold_clean.iterdir() if d.is_dir()]\n",
    "    \n",
    "    if not magazine_dirs:\n",
    "        print(\"No magazine directories found in cleaned/\")\n",
    "        return {}\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for mag_dir in sorted(magazine_dirs):\n",
    "        magazine_name = mag_dir.name\n",
    "        json_files = list(mag_dir.glob(\"*.json\"))\n",
    "        \n",
    "        if not json_files:\n",
    "            continue\n",
    "        \n",
    "        mag_results = {'valid': 0, 'invalid': 0, 'errors': {}}\n",
    "        \n",
    "        for json_file in sorted(json_files):\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                Stage1PageModel(**data)\n",
    "                mag_results['valid'] += 1\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                mag_results['invalid'] += 1\n",
    "                mag_results['errors'][json_file.name] = f\"JSON parse error: {e}\"\n",
    "                \n",
    "            except Exception as e:\n",
    "                mag_results['invalid'] += 1\n",
    "                mag_results['errors'][json_file.name] = str(e)\n",
    "        \n",
    "        results[magazine_name] = mag_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run validation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Validate Gold Standard\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "validation_results = validate_gold_standard(GOLD_CLEAN)\n",
    "\n",
    "if not validation_results:\n",
    "    print(\"No magazines found in cleaned/\")\n",
    "else:\n",
    "    for magazine_name, result in validation_results.items():\n",
    "        total = result['valid'] + result['invalid']\n",
    "        print(f\"{magazine_name}: {result['valid']}/{total} valid\")\n",
    "        \n",
    "        if result['errors']:\n",
    "            for filename, error in result['errors'].items():\n",
    "                print(f\"  ERROR: {filename}\")\n",
    "                print(f\"    {error}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Summary\")\n",
    "    print(\"=\" * 60)\n",
    "    total_valid = sum(r['valid'] for r in validation_results.values())\n",
    "    total_invalid = sum(r['invalid'] for r in validation_results.values())\n",
    "    print(f\"Valid:   {total_valid}\")\n",
    "    print(f\"Invalid: {total_invalid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Gold Standard Statistics\n",
      "============================================================\n",
      "\n",
      "La_Plume_bpt6k1185893k_1_10_1889:\n",
      "  Pages:      14\n",
      "  Items:      70\n",
      "  Avg/page:   5.0\n",
      "  Item classes:\n",
      "    paratext: 44 (62.9%)\n",
      "    prose: 14 (20.0%)\n",
      "    verse: 11 (15.7%)\n",
      "    ad: 1 (1.4%)\n",
      "  Text length:\n",
      "    Avg: 673 chars\n",
      "    Min: 2 chars\n",
      "    Max: 5222 chars\n",
      "  With title: 20\n",
      "  With author: 18\n",
      "  Top authors:\n",
      "    Léon Deschamps.: 2\n",
      "    Gustave Rivet.: 1\n",
      "    Francis Poictevin.: 1\n",
      "\n",
      "La_Plume_bpt6k1212187t_15-11-1893:\n",
      "  Pages:      1\n",
      "  Items:      3\n",
      "  Avg/page:   3.0\n",
      "  Item classes:\n",
      "    paratext: 2 (66.7%)\n",
      "    prose: 1 (33.3%)\n",
      "  Text length:\n",
      "    Avg: 1491 chars\n",
      "    Min: 24 chars\n",
      "    Max: 4406 chars\n",
      "  With title: 1\n",
      "\n",
      "============================================================\n",
      "Totals\n",
      "============================================================\n",
      "Magazines:  2\n",
      "Pages:      15\n",
      "Items:      73\n",
      "Item classes:\n",
      "  paratext: 46 (63.0%)\n",
      "  prose: 15 (20.5%)\n",
      "  verse: 11 (15.1%)\n",
      "  ad: 1 (1.4%)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compute Statistics for Gold Standard\n",
    "\"\"\"\n",
    "\n",
    "def compute_statistics(gold_clean: Path) -> Dict:\n",
    "    \"\"\"\n",
    "    Compute summary statistics for annotated gold standard.\n",
    "    \n",
    "    Args:\n",
    "        gold_clean: Gold standard cleaned directory\n",
    "    \n",
    "    Returns:\n",
    "        Statistics by magazine and totals\n",
    "    \"\"\"\n",
    "    magazine_dirs = [d for d in gold_clean.iterdir() if d.is_dir()]\n",
    "    \n",
    "    if not magazine_dirs:\n",
    "        print(\"No magazine directories found in cleaned/\")\n",
    "        return {}\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for mag_dir in sorted(magazine_dirs):\n",
    "        magazine_name = mag_dir.name\n",
    "        json_files = list(mag_dir.glob(\"*.json\"))\n",
    "        \n",
    "        if not json_files:\n",
    "            continue\n",
    "        \n",
    "        mag_stats = {\n",
    "            'pages': len(json_files),\n",
    "            'items': 0,\n",
    "            'item_classes': Counter(),\n",
    "            'authors': Counter(),\n",
    "            'with_title': 0,\n",
    "            'with_author': 0,\n",
    "            'text_lengths': []\n",
    "        }\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                items = data.get('items', [])\n",
    "                mag_stats['items'] += len(items)\n",
    "                \n",
    "                for item in items:\n",
    "                    mag_stats['item_classes'][item.get('item_class', 'unknown')] += 1\n",
    "                    \n",
    "                    if item.get('item_title'):\n",
    "                        mag_stats['with_title'] += 1\n",
    "                    \n",
    "                    if item.get('item_author'):\n",
    "                        mag_stats['with_author'] += 1\n",
    "                        mag_stats['authors'][item.get('item_author')] += 1\n",
    "                    \n",
    "                    text_len = len(item.get('item_text_raw', ''))\n",
    "                    mag_stats['text_lengths'].append(text_len)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"ERROR reading {json_file.name}: {e}\")\n",
    "        \n",
    "        results[magazine_name] = mag_stats\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Gold Standard Statistics\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "stats = compute_statistics(GOLD_CLEAN)\n",
    "\n",
    "if not stats:\n",
    "    print(\"No magazines found in cleaned/\")\n",
    "else:\n",
    "    # Per-magazine stats\n",
    "    for magazine_name, mag_stats in stats.items():\n",
    "        print(f\"{magazine_name}:\")\n",
    "        print(f\"  Pages:      {mag_stats['pages']}\")\n",
    "        print(f\"  Items:      {mag_stats['items']}\")\n",
    "        \n",
    "        if mag_stats['items'] > 0:\n",
    "            avg_items = mag_stats['items'] / mag_stats['pages']\n",
    "            print(f\"  Avg/page:   {avg_items:.1f}\")\n",
    "            \n",
    "            print(f\"  Item classes:\")\n",
    "            for item_class, count in mag_stats['item_classes'].most_common():\n",
    "                pct = count / mag_stats['items'] * 100\n",
    "                print(f\"    {item_class}: {count} ({pct:.1f}%)\")\n",
    "            \n",
    "            if mag_stats['text_lengths']:\n",
    "                avg_len = sum(mag_stats['text_lengths']) / len(mag_stats['text_lengths'])\n",
    "                print(f\"  Text length:\")\n",
    "                print(f\"    Avg: {avg_len:.0f} chars\")\n",
    "                print(f\"    Min: {min(mag_stats['text_lengths'])} chars\")\n",
    "                print(f\"    Max: {max(mag_stats['text_lengths'])} chars\")\n",
    "            \n",
    "            if mag_stats['with_title'] > 0:\n",
    "                print(f\"  With title: {mag_stats['with_title']}\")\n",
    "            if mag_stats['with_author'] > 0:\n",
    "                print(f\"  With author: {mag_stats['with_author']}\")\n",
    "            \n",
    "            if mag_stats['authors']:\n",
    "                print(f\"  Top authors:\")\n",
    "                for author, count in mag_stats['authors'].most_common(3):\n",
    "                    print(f\"    {author}: {count}\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # Totals\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Totals\")\n",
    "    print(\"=\" * 60)\n",
    "    total_pages = sum(s['pages'] for s in stats.values())\n",
    "    total_items = sum(s['items'] for s in stats.values())\n",
    "    print(f\"Magazines:  {len(stats)}\")\n",
    "    print(f\"Pages:      {total_pages}\")\n",
    "    print(f\"Items:      {total_items}\")\n",
    "    \n",
    "    if total_items > 0:\n",
    "        all_classes = Counter()\n",
    "        for s in stats.values():\n",
    "            all_classes.update(s['item_classes'])\n",
    "        \n",
    "        print(f\"Item classes:\")\n",
    "        for item_class, count in all_classes.most_common():\n",
    "            pct = count / total_items * 100\n",
    "            print(f\"  {item_class}: {count} ({pct:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magazine-graphs-py3.11 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
