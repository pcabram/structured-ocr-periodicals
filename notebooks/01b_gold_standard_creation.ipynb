{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold Standard Preparation - Stage 1\n",
      "============================================================\n",
      "Project root: /home/fabian-ramirez/Documents/These/Code/magazine_graphs\n",
      "\n",
      "Directories:\n",
      "  Predictions: /home/fabian-ramirez/Documents/These/Code/magazine_graphs/data/predictions\n",
      "  Gold raw:    /home/fabian-ramirez/Documents/These/Code/magazine_graphs/data/gold_standard/raw\n",
      "  Gold clean:  /home/fabian-ramirez/Documents/These/Code/magazine_graphs/data/gold_standard/cleaned\n",
      "  Schema:      Stage1PageModel\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gold Standard Preparation - Stage 1 OCR\n",
    "\n",
    "Prepares prediction files for manual annotation and validates corrected gold standard.\n",
    "\n",
    "Input:  Predictions from data/predictions/{magazine_name}/\n",
    "Output: Gold standard in data/gold_standard/{raw|cleaned}/{magazine_name}/\n",
    "Schema: schemas/stage1_page.py\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "from typing import Dict, List\n",
    "from collections import Counter\n",
    "\n",
    "# Project root detection\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if PROJECT_ROOT.name == \"notebooks\":\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "print(\"Gold Standard Preparation - Stage 1\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Add schemas to path\n",
    "SCHEMAS_DIR = PROJECT_ROOT / \"schemas\"\n",
    "if str(SCHEMAS_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SCHEMAS_DIR))\n",
    "\n",
    "# Import schema\n",
    "from stage1_page import Stage1PageModel\n",
    "\n",
    "# Directory structure\n",
    "PRED_ROOT = PROJECT_ROOT / \"data\" / \"predictions\"\n",
    "GOLD_ROOT = PROJECT_ROOT / \"data\" / \"gold_standard\"\n",
    "GOLD_RAW = GOLD_ROOT / \"raw\"\n",
    "GOLD_CLEAN = GOLD_ROOT / \"cleaned\"\n",
    "\n",
    "# Create directories\n",
    "for directory in (GOLD_ROOT, GOLD_RAW, GOLD_CLEAN):\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\nDirectories:\")\n",
    "print(f\"  Predictions: {PRED_ROOT}\")\n",
    "print(f\"  Gold raw:    {GOLD_RAW}\")\n",
    "print(f\"  Gold clean:  {GOLD_CLEAN}\")\n",
    "print(f\"  Schema:      {Stage1PageModel.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying predictions for annotation...\n",
      "\n",
      "✓ La_Plume_bpt6k1185893k_1_10_1889: 0 copied, 14 skipped\n",
      "✓ La_Plume_bpt6k1212187t_15-11-1893: 3 copied, 3 skipped\n",
      "\n",
      "============================================================\n",
      "Copy Summary\n",
      "============================================================\n",
      "Magazines processed: 2\n",
      "Files copied:        3\n",
      "Files skipped:       17\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Copy Predictions for Annotation\n",
    "\"\"\"\n",
    "\n",
    "def copy_for_annotation(\n",
    "    pred_root: Path,\n",
    "    gold_raw: Path,\n",
    "    overwrite: bool = False\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Copy prediction files to gold_standard/raw/ for annotation.\n",
    "    \n",
    "    Processes all magazine directories in predictions/.\n",
    "    Skips files that already exist unless overwrite=True.\n",
    "    \n",
    "    Args:\n",
    "        pred_root: Root predictions directory\n",
    "        gold_raw: Gold standard raw directory\n",
    "        overwrite: If True, overwrite existing files\n",
    "    \n",
    "    Returns:\n",
    "        Statistics: {magazine_name: {'copied': n, 'skipped': n}}\n",
    "    \"\"\"\n",
    "    # Find all magazine directories in predictions\n",
    "    magazine_dirs = [d for d in pred_root.iterdir() if d.is_dir()]\n",
    "    \n",
    "    if not magazine_dirs:\n",
    "        print(\"No magazine directories found in predictions/\")\n",
    "        return {}\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    for mag_dir in sorted(magazine_dirs):\n",
    "        magazine_name = mag_dir.name\n",
    "        dest_dir = gold_raw / magazine_name\n",
    "        dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        json_files = list(mag_dir.glob(\"*.json\"))\n",
    "        \n",
    "        if not json_files:\n",
    "            print(f\"Attention: {magazine_name}: No JSON files found\")\n",
    "            continue\n",
    "        \n",
    "        mag_stats = {'copied': 0, 'skipped': 0}\n",
    "        \n",
    "        for json_file in sorted(json_files):\n",
    "            dest_file = dest_dir / json_file.name\n",
    "            \n",
    "            if dest_file.exists() and not overwrite:\n",
    "                mag_stats['skipped'] += 1\n",
    "            else:\n",
    "                shutil.copy2(json_file, dest_file)\n",
    "                mag_stats['copied'] += 1\n",
    "        \n",
    "        stats[magazine_name] = mag_stats\n",
    "        \n",
    "        print(f\"✓ {magazine_name}: {mag_stats['copied']} copied, {mag_stats['skipped']} skipped\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Run copy\n",
    "print(\"Copying predictions for annotation...\")\n",
    "print()\n",
    "copy_stats = copy_for_annotation(PRED_ROOT, GOLD_RAW, overwrite=False)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"Copy Summary\")\n",
    "print(\"=\" * 60)\n",
    "total_copied = sum(s['copied'] for s in copy_stats.values())\n",
    "total_skipped = sum(s['skipped'] for s in copy_stats.values())\n",
    "print(f\"Magazines processed: {len(copy_stats)}\")\n",
    "print(f\"Files copied:        {total_copied}\")\n",
    "print(f\"Files skipped:       {total_skipped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Validate Gold Standard\n",
      "============================================================\n",
      "\n",
      "La_Plume_bpt6k1185893k_1_10_1889: 14/14 valid\n",
      "\n",
      "============================================================\n",
      "Summary\n",
      "============================================================\n",
      "Valid:   14\n",
      "Invalid: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Validate Gold Standard Files\n",
    "\"\"\"\n",
    "\n",
    "def validate_gold_standard(gold_clean: Path) -> Dict:\n",
    "    \"\"\"\n",
    "    Validate all JSON files in gold_standard/cleaned/ against schema.\n",
    "    \n",
    "    Args:\n",
    "        gold_clean: Gold standard cleaned directory\n",
    "    \n",
    "    Returns:\n",
    "        Validation results by magazine\n",
    "    \"\"\"\n",
    "    magazine_dirs = [d for d in gold_clean.iterdir() if d.is_dir()]\n",
    "    \n",
    "    if not magazine_dirs:\n",
    "        print(\"No magazine directories found in cleaned/\")\n",
    "        return {}\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for mag_dir in sorted(magazine_dirs):\n",
    "        magazine_name = mag_dir.name\n",
    "        json_files = list(mag_dir.glob(\"*.json\"))\n",
    "        \n",
    "        if not json_files:\n",
    "            continue\n",
    "        \n",
    "        mag_results = {'valid': 0, 'invalid': 0, 'errors': {}}\n",
    "        \n",
    "        for json_file in sorted(json_files):\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                Stage1PageModel(**data)\n",
    "                mag_results['valid'] += 1\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                mag_results['invalid'] += 1\n",
    "                mag_results['errors'][json_file.name] = f\"JSON parse error: {e}\"\n",
    "                \n",
    "            except Exception as e:\n",
    "                mag_results['invalid'] += 1\n",
    "                mag_results['errors'][json_file.name] = str(e)\n",
    "        \n",
    "        results[magazine_name] = mag_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run validation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Validate Gold Standard\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "validation_results = validate_gold_standard(GOLD_CLEAN)\n",
    "\n",
    "if not validation_results:\n",
    "    print(\"No magazines found in cleaned/\")\n",
    "else:\n",
    "    for magazine_name, result in validation_results.items():\n",
    "        total = result['valid'] + result['invalid']\n",
    "        print(f\"{magazine_name}: {result['valid']}/{total} valid\")\n",
    "        \n",
    "        if result['errors']:\n",
    "            for filename, error in result['errors'].items():\n",
    "                print(f\"  ERROR: {filename}\")\n",
    "                print(f\"    {error}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Summary\")\n",
    "    print(\"=\" * 60)\n",
    "    total_valid = sum(r['valid'] for r in validation_results.values())\n",
    "    total_invalid = sum(r['invalid'] for r in validation_results.values())\n",
    "    print(f\"Valid:   {total_valid}\")\n",
    "    print(f\"Invalid: {total_invalid}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magazine-graphs-py3.11 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
