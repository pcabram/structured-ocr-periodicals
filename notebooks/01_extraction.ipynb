{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c08446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabian-ramirez/Documents/These/Code/magazine_graphs/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import logging\n",
    "import sys\n",
    "import time, random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Literal\n",
    "\n",
    "\n",
    "from pypdf import PdfReader\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from mistralai import Mistral\n",
    "from mistralai.extra import response_format_from_pydantic_model\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    tqdm = lambda x, **_: x\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    ")\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if PROJECT_ROOT.name == \"notebooks\":\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c73eb107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-13 17:04:49,468 | INFO | Project root: /home/fabian-ramirez/Documents/These/Code/magazine_graphs\n",
      "2025-10-13 17:04:49,470 | INFO | SRC_ROOT=/home/fabian-ramirez/Documents/These/Code/magazine_graphs/data/raw | DST_PAGES=/home/fabian-ramirez/Documents/These/Code/magazine_graphs/data/interim_pages\n"
     ]
    }
   ],
   "source": [
    "# Data locations\n",
    "SRC_ROOT = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "DST_PAGES = PROJECT_ROOT / \"data\" / \"interim_pages\"   # <-- where page JSONs will be written\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for p in (SRC_ROOT, DST_PAGES):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "ZERO_PAD: int = 3\n",
    "OVERWRITE: bool = False\n",
    "MAX_PAGES_PER_OCR_REQUEST: int = 8  # SDK limit\n",
    "\n",
    "# Logger for this notebook\n",
    "logger = logging.getLogger(\"notebook.ocr\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info(\"Project root: %s\", PROJECT_ROOT)\n",
    "logger.info(\"SRC_ROOT=%s | DST_PAGES=%s\", SRC_ROOT, DST_PAGES)\n",
    "\n",
    "# Secrets & client init\n",
    "def read_api_key(\n",
    "    env_var: str = \"MISTRAL_API_KEY\",\n",
    "    fallback_file: Path = PROJECT_ROOT / \"api_key\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Read API key from environment or from a local 'api_key' file at project root.\n",
    "    \"\"\"\n",
    "    key = os.environ.get(env_var)\n",
    "    if key:\n",
    "        return key.strip()\n",
    "    if fallback_file.exists():\n",
    "        return fallback_file.read_text(encoding=\"utf-8\").strip()\n",
    "    raise RuntimeError(\n",
    "        f\"{env_var} not set and fallback file '{fallback_file}' not found.\"\n",
    "    )\n",
    "\n",
    "def get_mistral_client() -> Mistral:\n",
    "    \"\"\"\n",
    "    Lazily construct the Mistral OCR client (won't run until you call it).\n",
    "    \"\"\"\n",
    "    return Mistral(api_key=read_api_key())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31d488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-13 17:04:52,185 | INFO | Loaded schema: Stage1PageModel\n"
     ]
    }
   ],
   "source": [
    "# Import Stage 1 schema from schemas directory\n",
    "\n",
    "# Add schemas directory to Python path\n",
    "SCHEMAS_DIR = PROJECT_ROOT / \"schemas\"\n",
    "if str(SCHEMAS_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SCHEMAS_DIR))\n",
    "\n",
    "# Import the schema (choose which version to use)\n",
    "# Option 1: WITH continuation fields\n",
    "from stage1_page import Stage1PageModel\n",
    "\n",
    "# Option 2: WITHOUT continuation fields (comment out Option 1, uncomment this)\n",
    "# from stage1_page_no_continuation import Stage1PageModelNoContinuation as Stage1PageModel\n",
    "\n",
    "logger.info(\"Loaded schema: %s\", Stage1PageModel.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a2bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_ANNOT_FMT = response_format_from_pydantic_model(Stage1PageModel)\n",
    "\n",
    "def count_pages(pdf_path: Path) -> int:\n",
    "    try:\n",
    "        with pdf_path.open(\"rb\") as fh:\n",
    "            try:\n",
    "                reader = PdfReader(fh, strict=False)\n",
    "            except TypeError:\n",
    "                reader = PdfReader(fh)  # fallback if 'strict' arg unsupported\n",
    "            if getattr(reader, \"is_encrypted\", False) and reader.decrypt(\"\") == 0:\n",
    "                logger.warning(\"Encrypted PDF (cannot decrypt): %s\", pdf_path)\n",
    "                return 0\n",
    "            return len(reader.pages)\n",
    "    except Exception as e:\n",
    "        logger.warning(\"Could not read %s: %s\", pdf_path, e)\n",
    "        return 0\n",
    "\n",
    "def encode_file_to_data_url(path: Path, mime: str = \"application/pdf\") -> str:\n",
    "    b64 = base64.b64encode(path.read_bytes()).decode(\"utf-8\")\n",
    "    return f\"data:{mime};base64,{b64}\"\n",
    "\n",
    "def chunks(seq, size):\n",
    "    for i in range(0, len(seq), size):\n",
    "        yield seq[i:i+size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b2c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_single_annotation(resp) -> dict:\n",
    "    \"\"\"\n",
    "    Extract one page's annotation from a single-page request response.\n",
    "    Prefer resp.document_annotation; fall back to resp.pages[0].document_annotation.\n",
    "    \"\"\"\n",
    "    ann = getattr(resp, \"document_annotation\", None)\n",
    "    if isinstance(ann, str):\n",
    "        try:\n",
    "            return json.loads(ann)\n",
    "        except Exception:\n",
    "            pass\n",
    "    elif isinstance(ann, dict):\n",
    "        return ann or {}\n",
    "\n",
    "    pages = getattr(resp, \"pages\", None) or []\n",
    "    if pages:\n",
    "        raw = getattr(pages[0], \"document_annotation\", None)\n",
    "        if isinstance(raw, str):\n",
    "            try:\n",
    "                return json.loads(raw)\n",
    "            except Exception:\n",
    "                return {}\n",
    "        elif isinstance(raw, dict):\n",
    "            return raw or {}\n",
    "    return {}\n",
    "\n",
    "def call_with_retry(fn, *, retries: int = 3, base_delay: float = 1.0, max_delay: float = 8.0):\n",
    "    \"\"\"Simple exponential backoff with jitter for transient API errors.\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            return fn()\n",
    "        except Exception as e:\n",
    "            if attempt == retries - 1:\n",
    "                raise\n",
    "            delay = min(max_delay, base_delay * (2 ** attempt)) * (1 + 0.25 * random.random())\n",
    "            logger.warning(\"Call failed (%s). Retrying in %.1fs...\", e, delay)\n",
    "            time.sleep(delay)\n",
    "\n",
    "def _prune_empty_fields(d: dict) -> dict:\n",
    "    \"\"\"Remove keys with None/empty values, but keep 'items' even if empty list.\"\"\"\n",
    "    if not isinstance(d, dict):\n",
    "        return {}\n",
    "    out = {}\n",
    "    for k, v in d.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        if isinstance(v, str) and v.strip() == \"\":\n",
    "            continue\n",
    "        if isinstance(v, list):\n",
    "            out[k] = v  # keep list, even empty\n",
    "        elif isinstance(v, dict):\n",
    "            pruned = _prune_empty_fields(v)\n",
    "            if pruned:\n",
    "                out[k] = pruned\n",
    "        else:\n",
    "            out[k] = v\n",
    "    return out\n",
    "\n",
    "def annotate_pdf_per_page(\n",
    "    pdf_path: Path,\n",
    "    out_root: Path = DST_PAGES,\n",
    "    model_name: str = \"mistral-ocr-latest\",\n",
    "    overwrite: bool = OVERWRITE,\n",
    ") -> int:\n",
    "    \"\"\"Call Document Annotation once per page and write one JSON per page.\n",
    "    Only keep fields/text that the model explicitly extracts from the page.\n",
    "    \"\"\"\n",
    "    n_pages = count_pages(pdf_path)\n",
    "    if n_pages == 0:\n",
    "        return 0\n",
    "\n",
    "    rel_no_ext = pdf_path.relative_to(SRC_ROOT).with_suffix(\"\")\n",
    "    out_dir = out_root / rel_no_ext\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    data_url = encode_file_to_data_url(pdf_path)\n",
    "    client = get_mistral_client()\n",
    "\n",
    "    written = 0\n",
    "    for page_idx in tqdm(range(n_pages), desc=f\"Annotating (per-page) {pdf_path.name}\", leave=False):\n",
    "        out_json = out_dir / f\"{pdf_path.stem}__page-{page_idx+1:0{ZERO_PAD}d}.json\"\n",
    "        if out_json.exists() and not overwrite:\n",
    "            continue\n",
    "\n",
    "        def _call():\n",
    "            return client.ocr.process(\n",
    "                model=model_name,\n",
    "                document={\"type\": \"document_url\", \"document_url\": data_url},\n",
    "                pages=[page_idx],\n",
    "                document_annotation_format=DOC_ANNOT_FMT,\n",
    "                include_image_base64=False,\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            resp = call_with_retry(_call)\n",
    "        except Exception as e:\n",
    "            logger.warning(\"Page %d of %s failed after retries: %s\", page_idx + 1, pdf_path.name, e)\n",
    "            continue\n",
    "\n",
    "        annot = parse_single_annotation(resp) or {}\n",
    "        # Ensure items key exists, but don't fabricate other fields\n",
    "        if \"items\" not in annot:\n",
    "            annot[\"items\"] = []\n",
    "\n",
    "        # Drop synthetic/default fields; keep only what's present\n",
    "        annot = _prune_empty_fields(annot)\n",
    "\n",
    "        try:\n",
    "            out_json.write_text(json.dumps(annot, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "            written += 1\n",
    "        except Exception as e:\n",
    "            logger.warning(\"Failed to write %s: %s\", out_json, e)\n",
    "\n",
    "    logger.info(\"Per-page annotated %s â†’ %d/%d JSONs\", pdf_path.name, written, n_pages)\n",
    "    return written\n",
    "\n",
    "def annotate_all_pdfs_per_page(src_root: Path = SRC_ROOT) -> int:\n",
    "    total = 0\n",
    "    for pdf in tqdm([p for p in src_root.rglob(\"*.pdf\") if p.is_file()], desc=\"Annotating PDFs (per-page)\"):\n",
    "        total += annotate_pdf_per_page(pdf)\n",
    "    logger.info(\"Total per-page annotated JSONs: %d\", total)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff57818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run (set OVERWRITE=True first if you need to replace existing files)\n",
    "# OVERWRITE = True\n",
    "total_per_page = annotate_all_pdfs_per_page()\n",
    "total_per_page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magazine-graphs-py3.11 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
