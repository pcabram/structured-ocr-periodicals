{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b25e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified Extraction - Stage 1\n",
      "============================================================\n",
      "Project root: /home/fabian-ramirez/Documents/These/Code/magazine_graphs\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imports and Setup\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Tuple\n",
    "\n",
    "# Project imports\n",
    "from utils.paths import (\n",
    "    PROJECT_ROOT,\n",
    "    RAW_DATA,\n",
    "    PREDICTIONS,\n",
    "    build_evaluation_path,\n",
    "    discover_available_magazines,\n",
    "    discover_existing_extractions,\n",
    "    generate_all_combinations,\n",
    "    calculate_missing_extractions\n",
    ")\n",
    "from utils.config import MISTRAL_CONFIG, EXTRACTION_CONFIG\n",
    "from utils.extraction import extract_pdf_pages\n",
    "from mistralai import Mistral\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(\"unified_extraction\")\n",
    "\n",
    "print(\"Unified Extraction - Stage 1\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "797465b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODE: AUTOMATIC\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Mode Selection\n",
    "\n",
    "Choose your extraction mode:\n",
    "- 'manual': You specify everything (magazines, model, schema, prompt)\n",
    "- 'automatic': Auto-discovers everything, extracts missing combinations\n",
    "\"\"\"\n",
    "\n",
    "MODE = \"automatic\"  # \"manual\" or \"automatic\" for auto-discovery mode\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"MODE: {MODE.upper()}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93f7979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Manual Mode Configuration\n",
    "\n",
    "Specify exactly what to extract:\n",
    "- MAGAZINES: List of PDF names (without .pdf extension)\n",
    "- MODELS: List of model names\n",
    "- SCHEMAS: List of schema names\n",
    "- PROMPTS: List of prompt names (use [] for OCR-only models)\n",
    "\"\"\"\n",
    "\n",
    "if MODE == \"manual\":\n",
    "    # ========================================\n",
    "    # EDIT THIS SECTION FOR MANUAL MODE\n",
    "    # ========================================\n",
    "    \n",
    "    # Magazines to extract (PDF filenames without .pdf)\n",
    "    MAGAZINES = [\n",
    "        \"La_Plume_minimal_test\",\n",
    "        # Add more magazines here\n",
    "    ]\n",
    "    \n",
    "    # Models to use (can be multiple)\n",
    "    MODELS = [\n",
    "        # \"pixtral-large-latest\",\n",
    "        \"mistral-ocr-latest\",\n",
    "        \"pixtral-12b-latest\",\n",
    "    ]\n",
    "    \n",
    "    # Schemas to use (can be multiple)\n",
    "    SCHEMAS = [\n",
    "        \"stage1_page\",\n",
    "        \"stage1_page_v2\",\n",
    "        # Add more schemas here\n",
    "    ]\n",
    "    \n",
    "    # Prompts to use (can be multiple, use [] for OCR-only)\n",
    "    PROMPTS = [\n",
    "        \"stage1_page_v2\",\n",
    "        # \"detailed_v1\",\n",
    "        # Add more prompts here\n",
    "    ]\n",
    "    \n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\\nManual Mode Configuration:\")\n",
    "    print(f\"  Magazines: {len(MAGAZINES)}\")\n",
    "    for mag in MAGAZINES:\n",
    "        print(f\"    - {mag}\")\n",
    "    print(f\"\\n  Models: {len(MODELS)}\")\n",
    "    for model in MODELS:\n",
    "        print(f\"    - {model}\")\n",
    "    print(f\"\\n  Schemas: {len(SCHEMAS)}\")\n",
    "    for schema in SCHEMAS:\n",
    "        print(f\"    - {schema}\")\n",
    "    print(f\"\\n  Prompts: {len(PROMPTS)}\")\n",
    "    if PROMPTS:\n",
    "        for prompt in PROMPTS:\n",
    "            print(f\"    - {prompt}\")\n",
    "    else:\n",
    "        print(f\"    - (none - OCR only)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98d0b1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Automatic Mode - Discovering resources...\n",
      "\n",
      "Discovered 2 magazine(s) in /home/fabian-ramirez/Documents/These/Code/magazine_graphs/data/raw:\n",
      "  - La_Plume_bpt6k1185893k_1_10_1889\n",
      "  - La_Plume_bpt6k1212187t_15-11-1893\n",
      "\n",
      "Discovered 7 schema(s) in /home/fabian-ramirez/Documents/These/Code/magazine_graphs/schemas:\n",
      "  - stage1_page\n",
      "  - stage1_page_v2\n",
      "  - stage1_page_v2_medium\n",
      "  - stage1_page_v2_medium_pure\n",
      "  - stage1_page_v2_pure\n",
      "  - stage1_page_v2_small\n",
      "  - stage1_page_v2_small_pure\n",
      "\n",
      "Discovered 2 prompt(s) in /home/fabian-ramirez/Documents/These/Code/magazine_graphs/prompts:\n",
      "  - stage1_page_v2\n",
      "  - stage1_page_v2_pure\n",
      "\n",
      "Using 3 model(s):\n",
      "  - mistral-ocr-latest\n",
      "  - pixtral-12b-latest\n",
      "  - pixtral-large-latest\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Automatic Mode - Auto-Discovery\n",
    "\n",
    "Discovers everything from your project:\n",
    "- Magazines: from data/raw/*.pdf\n",
    "- Schemas: from schemas/*.py\n",
    "- Prompts: from prompts/*.txt\n",
    "- Models: from hardcoded list (OCR + Vision)\n",
    "\"\"\"\n",
    "\n",
    "if MODE == \"automatic\":\n",
    "    print(\"\\nAutomatic Mode - Discovering resources...\")\n",
    "    print()\n",
    "    \n",
    "    # Discover magazines from data/raw/\n",
    "    MAGAZINES = discover_available_magazines(RAW_DATA)\n",
    "    print(f\"Discovered {len(MAGAZINES)} magazine(s) in {RAW_DATA}:\")\n",
    "    for mag in MAGAZINES:\n",
    "        print(f\"  - {mag}\")\n",
    "    print()\n",
    "    \n",
    "    # Discover schemas from schemas/ directory\n",
    "    schemas_dir = PROJECT_ROOT / \"schemas\"\n",
    "    schema_files = sorted(schemas_dir.glob(\"stage1_*.py\"))\n",
    "    SCHEMAS = [f.stem for f in schema_files if not f.stem.endswith(\"__init__\")]\n",
    "    print(f\"Discovered {len(SCHEMAS)} schema(s) in {schemas_dir}:\")\n",
    "    for schema in SCHEMAS:\n",
    "        print(f\"  - {schema}\")\n",
    "    print()\n",
    "    \n",
    "    # Discover prompts from prompts/ directory\n",
    "    prompts_dir = PROJECT_ROOT / \"prompts\"\n",
    "    prompt_files = sorted(prompts_dir.glob(\"*.txt\")) if prompts_dir.exists() else []\n",
    "    PROMPTS = [f.stem for f in prompt_files]\n",
    "    print(f\"Discovered {len(PROMPTS)} prompt(s) in {prompts_dir}:\")\n",
    "    for prompt in PROMPTS:\n",
    "        print(f\"  - {prompt}\")\n",
    "    print()\n",
    "    \n",
    "    # Hardcoded models list (OCR + Vision)\n",
    "    MODELS = [\n",
    "        \"mistral-ocr-latest\",\n",
    "        \"pixtral-12b-latest\",\n",
    "        \"pixtral-large-latest\",\n",
    "    ]\n",
    "    print(f\"Using {len(MODELS)} model(s):\")\n",
    "    for model in MODELS:\n",
    "        print(f\"  - {model}\")\n",
    "    print()\n",
    "    \n",
    "    # Check for missing resources\n",
    "    if not MAGAZINES:\n",
    "        print(\"WARNING: No magazines found in data/raw/\")\n",
    "    if not SCHEMAS:\n",
    "        print(\"WARNING: No schemas found in schemas/\")\n",
    "    if not PROMPTS:\n",
    "        print(\"WARNING: No prompts found in prompts/ (OCR models will still work)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3708865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXTRACTION PLANNING\n",
      "============================================================\n",
      "\n",
      "Calculating missing extractions...\n",
      "\n",
      "Found 0 existing extraction(s)\n",
      "Expected 70 total extraction(s)\n",
      "\n",
      "Missing 70 extraction(s) (need to run)\n",
      "  OCR:    14\n",
      "  Vision: 56\n",
      "\n",
      "Will extract 70 combination(s)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Planning & Missing Calculation\n",
    "\n",
    "Calculate what needs to be extracted:\n",
    "- Manual mode: Generate extraction plan from configuration\n",
    "- Automatic mode: Calculate missing = (expected - existing)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACTION PLANNING\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "if MODE == \"manual\":\n",
    "    # Manual mode: generate all combinations from specified lists\n",
    "    try:\n",
    "        planned_extractions = generate_all_combinations(\n",
    "            magazines=MAGAZINES,\n",
    "            models=MODELS,\n",
    "            schemas=SCHEMAS,\n",
    "            prompts=PROMPTS)\n",
    "\n",
    "        print(f\"Manual mode: Planning {len(planned_extractions)} extraction(s)\")\n",
    "        print(f\"  Magazines:  {len(MAGAZINES)}\")\n",
    "        print(f\"  Models:     {len(MODELS)}\")\n",
    "        print(f\"  Schema:     {len(SCHEMAS)}\")\n",
    "        print(f\"  Prompt:     {len(PROMPTS) if PROMPTS else 0}\")\n",
    "\n",
    "        # Breakdown\n",
    "        ocr_extractions = [e for e in planned_extractions if e[3] is None]\n",
    "        vision_extractions = [e for e in planned_extractions if e[3] is not None]\n",
    "\n",
    "        if ocr_extractions:\n",
    "            print(f\"\\n  OCR Extractions:    {len(ocr_extractions)}\")\n",
    "        if vision_extractions:\n",
    "            print(f\"  Vision Extractions: {len(vision_extractions)}\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nWARNING ERROR: {e}\")\n",
    "        print(\"\\nFor vision models, add prompt files to PROMPTS list\")\n",
    "        raise\n",
    "    \n",
    "elif MODE == \"automatic\":\n",
    "    # Automatic mode: calculate missing extractions\n",
    "    print(\"Calculating missing extractions...\")\n",
    "    print()\n",
    "    \n",
    "    # What already exists?\n",
    "    existing = discover_existing_extractions(PREDICTIONS / \"evaluations\")\n",
    "    print(f\"Found {len(existing)} existing extraction(s)\")\n",
    "    \n",
    "    # What should exist?\n",
    "    try:\n",
    "        expected = generate_all_combinations(MAGAZINES, MODELS, SCHEMAS, PROMPTS)\n",
    "        print(f\"Expected {len(expected)} total extraction(s)\")\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nWARNING  ERROR: {e}\")\n",
    "        print(\"\\nPlease add prompt files to prompts/ directory or use manual mode.\")\n",
    "        raise\n",
    "    \n",
    "    # What's missing?\n",
    "    planned_extractions = expected - existing\n",
    "    print(f\"\\nMissing {len(planned_extractions)} extraction(s) (need to run)\")\n",
    "    \n",
    "    # Breakdown\n",
    "    ocr_extractions = [e for e in planned_extractions if e[3] is None]\n",
    "    vision_extractions = [e for e in planned_extractions if e[3] is not None]\n",
    "    \n",
    "    print(f\"  OCR:    {len(ocr_extractions)}\")\n",
    "    print(f\"  Vision: {len(vision_extractions)}\")\n",
    "\n",
    "print()\n",
    "print(f\"Will extract {len(planned_extractions)} combination(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "004dabdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXTRACTION PREVIEW\n",
      "============================================================\n",
      "\n",
      "Planned extractions: 70\n",
      "\n",
      "Magazine                            Model                     Schema               Prompt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "La_Plume_bpt6k1185893k_1_10_1889    mistral-ocr-latest        stage1_page_v2_small_pure none\n",
      "La_Plume_bpt6k1185893k_1_10_1889    pixtral-12b-latest        stage1_page_v2       stage1_page_v2\n",
      "La_Plume_bpt6k1185893k_1_10_1889    pixtral-12b-latest        stage1_page_v2_medium stage1_page_v2\n",
      "La_Plume_bpt6k1185893k_1_10_1889    pixtral-12b-latest        stage1_page_v2_small_pure stage1_page_v2_pure\n",
      "La_Plume_bpt6k1185893k_1_10_1889    pixtral-large-latest      stage1_page_v2_medium stage1_page_v2\n",
      "La_Plume_bpt6k1212187t_15-11-1893   pixtral-12b-latest        stage1_page_v2_medium_pure stage1_page_v2_pure\n",
      "La_Plume_bpt6k1212187t_15-11-1893   pixtral-12b-latest        stage1_page_v2_pure  stage1_page_v2\n",
      "La_Plume_bpt6k1212187t_15-11-1893   pixtral-12b-latest        stage1_page_v2_small stage1_page_v2\n",
      "La_Plume_bpt6k1212187t_15-11-1893   pixtral-12b-latest        stage1_page_v2_small stage1_page_v2_pure\n",
      "La_Plume_bpt6k1212187t_15-11-1893   pixtral-large-latest      stage1_page_v2_small_pure stage1_page_v2\n",
      "... and 60 more\n",
      "\n",
      "Output directory: /home/fabian-ramirez/Documents/These/Code/magazine_graphs/data/predictions/evaluations\n",
      "Structure: {magazine}/model={model}/schema={schema}/prompt={prompt}/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extraction Preview\n",
    "\n",
    "Display what will be extracted before running.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACTION PREVIEW\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "if len(planned_extractions) == 0:\n",
    "    print(\"✓ Nothing to extract - all combinations already exist!\")\n",
    "    print()\n",
    "    print(\"You can:\")\n",
    "    print(\"  - Set EXTRACTION_CONFIG.overwrite = True to re-extract\")\n",
    "    print(\"  - Add new prompts/schemas and run automatic mode again\")\n",
    "    print(\"  - Switch to manual mode for specific extractions\")\n",
    "else:\n",
    "    # Group by magazine for clearer display\n",
    "    from collections import defaultdict\n",
    "    by_magazine = defaultdict(list)\n",
    "    \n",
    "    for mag, model, schema, prompt in sorted(planned_extractions):\n",
    "        by_magazine[mag].append((model, schema, prompt))\n",
    "    \n",
    "    print(f\"Planned extractions: {len(planned_extractions)}\")\n",
    "    print()\n",
    "    \n",
    "    # Show first 10 or all if <= 10\n",
    "    items_to_show = list(planned_extractions)[:10]\n",
    "    \n",
    "    print(f\"{'Magazine':<35} {'Model':<25} {'Schema':<20} {'Prompt'}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for mag, model, schema, prompt in sorted(items_to_show):\n",
    "        prompt_str = prompt or \"none\"\n",
    "        print(f\"{mag:<35} {model:<25} {schema:<20} {prompt_str}\")\n",
    "    \n",
    "    if len(planned_extractions) > 10:\n",
    "        print(f\"... and {len(planned_extractions) - 10} more\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"Output directory: {PREDICTIONS / 'evaluations'}\")\n",
    "    print(f\"Structure: {{magazine}}/model={{model}}/schema={{schema}}/prompt={{prompt}}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4d0ca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "API SETUP\n",
      "============================================================\n",
      "✓ Mistral client initialized\n",
      "✓ API key configured\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "API Client Setup\n",
    "\"\"\"\n",
    "\n",
    "def get_mistral_client() -> Mistral:\n",
    "    \"\"\"Initialize Mistral client with API key.\"\"\"\n",
    "    return Mistral(api_key=MISTRAL_CONFIG.get_api_key())\n",
    "\n",
    "client = get_mistral_client()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"API SETUP\")\n",
    "print(\"=\" * 60)\n",
    "print(\"✓ Mistral client initialized\")\n",
    "print(\"✓ API key configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e4de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 18:19:06,389 | INFO | Using provider architecture for extraction with model: mistral-ocr-latest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXECUTING EXTRACTIONS\n",
      "============================================================\n",
      "\n",
      "\n",
      "[1/70] ==================================================\n",
      "Magazine: La_Plume_bpt6k1185893k_1_10_1889\n",
      "Model:    mistral-ocr-latest\n",
      "Schema:   stage1_page\n",
      "Prompt:   none\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 18:19:06,506 | INFO | Processing La_Plume_bpt6k1185893k_1_10_1889.pdf: 14 to extract, 0 already exist\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e7bcbf09924e74905a7d5bc1d66cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  La_Plume_bpt6k1185893k_1_10_1889.pdf:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 18:19:18,011 | INFO | HTTP Request: POST https://api.mistral.ai/v1/ocr \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Execute Extractions\n",
    "\n",
    "Run extractions for all planned combinations.\n",
    "Progress tracked per extraction with statistics.\n",
    "\"\"\"\n",
    "\n",
    "if len(planned_extractions) == 0:\n",
    "    print(\"\\nSkipping extraction - nothing to do\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EXECUTING EXTRACTIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    # Track results\n",
    "    all_results = []\n",
    "    \n",
    "    for idx, (magazine, model, schema, prompt) in enumerate(sorted(planned_extractions), 1):\n",
    "        print(f\"\\n[{idx}/{len(planned_extractions)}] \" + \"=\" * 50)\n",
    "        prompt_str = prompt or \"none\"\n",
    "        print(f\"Magazine: {magazine}\")\n",
    "        print(f\"Model:    {model}\")\n",
    "        print(f\"Schema:   {schema}\")\n",
    "        print(f\"Prompt:   {prompt_str}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Load schema class dynamically\n",
    "        try:\n",
    "            schema_module = importlib.import_module(f\"schemas.{schema}\")\n",
    "            schema_class = schema_module.Stage1PageModel\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load schema '{schema}': {e}\")\n",
    "            all_results.append({\n",
    "                \"magazine\": magazine,\n",
    "                \"model\": model,\n",
    "                \"schema\": schema,\n",
    "                \"prompt\": prompt,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Build output path (magazine-first structure)\n",
    "        out_root = build_evaluation_path(\n",
    "            magazine_name=magazine,\n",
    "            model_name=model,\n",
    "            schema_name=schema,\n",
    "            prompt_name=prompt\n",
    "        )\n",
    "        \n",
    "        # Find PDF file\n",
    "        pdf_path = None\n",
    "        for pdf_file in RAW_DATA.rglob(f\"{magazine}.pdf\"):\n",
    "            pdf_path = pdf_file\n",
    "            break\n",
    "        \n",
    "        if pdf_path is None:\n",
    "            logger.error(f\"PDF not found: {magazine}.pdf\")\n",
    "            all_results.append({\n",
    "                \"magazine\": magazine,\n",
    "                \"model\": model,\n",
    "                \"schema\": schema,\n",
    "                \"prompt\": prompt,\n",
    "                \"error\": \"PDF not found\"\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Run extraction\n",
    "        try:\n",
    "            stats = extract_pdf_pages(\n",
    "                pdf_path=pdf_path,\n",
    "                schema_class=schema_class,\n",
    "                client=client,\n",
    "                out_root=out_root,\n",
    "                model_name=model,\n",
    "                prompt_name=prompt,\n",
    "                overwrite=EXTRACTION_CONFIG.overwrite,\n",
    "                zero_pad=EXTRACTION_CONFIG.zero_pad,\n",
    "                max_retries=MISTRAL_CONFIG.max_retries,\n",
    "                base_delay=MISTRAL_CONFIG.base_delay,\n",
    "                max_delay=MISTRAL_CONFIG.max_delay,\n",
    "                use_providers=True\n",
    "            )\n",
    "            \n",
    "            all_results.append({\n",
    "                \"magazine\": magazine,\n",
    "                \"model\": model,\n",
    "                \"schema\": schema,\n",
    "                \"prompt\": prompt,\n",
    "                \"written\": stats['written'],\n",
    "                \"skipped\": stats['skipped'],\n",
    "                \"failed\": stats['failed'],\n",
    "                \"total\": stats['total']\n",
    "            })\n",
    "            \n",
    "            print(f\"\\n✓ Extraction complete\")\n",
    "            print(f\"  Written: {stats['written']}\")\n",
    "            print(f\"  Skipped: {stats['skipped']}\")\n",
    "            print(f\"  Failed:  {stats['failed']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Extraction failed: {e}\")\n",
    "            all_results.append({\n",
    "                \"magazine\": magazine,\n",
    "                \"model\": model,\n",
    "                \"schema\": schema,\n",
    "                \"prompt\": prompt,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EXTRACTION COMPLETE\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891e442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Results Summary\n",
    "\"\"\"\n",
    "\n",
    "if len(planned_extractions) > 0:\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RESULTS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    # Check for errors\n",
    "    if 'error' in df.columns:\n",
    "        errors = df[df['error'].notna()]\n",
    "        if len(errors) > 0:\n",
    "            print(f\"WARNING  {len(errors)} extraction(s) failed:\")\n",
    "            print()\n",
    "            for _, row in errors.iterrows():\n",
    "                prompt_str = row['prompt'] or 'none'\n",
    "                print(f\"  {row['magazine']} / {row['model']} / {row['schema']} / {prompt_str}\")\n",
    "                print(f\"    Error: {row['error']}\")\n",
    "            print()\n",
    "    \n",
    "    # Successful extractions\n",
    "    successful = df[df.get('written', pd.Series()).notna()]\n",
    "    if len(successful) > 0:\n",
    "        print(f\"✓ {len(successful)} extraction(s) completed successfully\")\n",
    "        print()\n",
    "        print(f\"  Total pages written: {successful['written'].sum()}\")\n",
    "        print(f\"  Total pages skipped: {successful['skipped'].sum()}\")\n",
    "        print(f\"  Total pages failed:  {successful['failed'].sum()}\")\n",
    "        print()\n",
    "        \n",
    "        # Group by magazine\n",
    "        print(\"By magazine:\")\n",
    "        for magazine in sorted(successful['magazine'].unique()):\n",
    "            mag_data = successful[successful['magazine'] == magazine]\n",
    "            print(f\"\\n  {magazine}:\")\n",
    "            for _, row in mag_data.iterrows():\n",
    "                prompt_str = row['prompt'] or 'none'\n",
    "                print(f\"    {row['model']} × {row['schema']} × {prompt_str}\")\n",
    "                print(f\"      Written: {row['written']}, Skipped: {row['skipped']}, Failed: {row['failed']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Output directory:\")\n",
    "    print(f\"  {PREDICTIONS / 'evaluations'}\")\n",
    "    print()\n",
    "    print(\"Next step: Run evaluation notebook (01g_master_evaluation.ipynb)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Display full results table\n",
    "    print(\"\\nFull results:\")\n",
    "    display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magazine-graphs-py3.11 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
